{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подключение к Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 10:59:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Имя хоста Spark Master в docker\n",
    "SPARK_MASTER_HOST = \"spark-master\"\n",
    "# Порт Spark Master\n",
    "SPARK_MASTER_PORT = \"7077\"\n",
    "# Память выделенная для Spark Worker в настройках docker-compose.yml\n",
    "SPARK_WORKER_MEMORY = \"512m\"\n",
    "# Название сессии (любое)\n",
    "SPARK_SESSION = \"pyspark-notebook\"\n",
    "\n",
    "# Создаем сессию\n",
    "spark = (\n",
    "    SparkSession.builder.appName(SPARK_SESSION)\n",
    "    .master(f\"spark://{SPARK_MASTER_HOST}:{SPARK_MASTER_PORT}\")\n",
    "    .config(\"spark.executor.memory\", SPARK_WORKER_MEMORY)\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:59:48.717300Z",
     "end_time": "2023-04-02T13:59:51.693692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Чтение в Spark из Jupyter workspace\n",
    "\n",
    "Прочитать файл в Spark можно из рабочей директории Jupyter Lab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:28:33.332357Z",
     "end_time": "2023-04-02T13:28:33.501177Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001B[0m, in \u001B[0;36mBaseFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    342\u001B[0m     method \u001B[38;5;241m=\u001B[39m get_real_method(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_method)\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 344\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:336\u001B[0m, in \u001B[0;36mSparkSession._repr_html_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_repr_html_\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;124m        <div>\u001B[39m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124m            <p><b>SparkSession - \u001B[39m\u001B[38;5;132;01m{catalogImplementation}\u001B[39;00m\u001B[38;5;124m</b></p>\u001B[39m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124m            \u001B[39m\u001B[38;5;132;01m{sc_HTML}\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;124m        </div>\u001B[39m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    335\u001B[0m         catalogImplementation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.sql.catalogImplementation\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m--> 336\u001B[0m         sc_HTML\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_repr_html_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    337\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/pyspark/context.py:378\u001B[0m, in \u001B[0;36mSparkContext._repr_html_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_repr_html_\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m--> 378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;124;43m    <div>\u001B[39;49m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;124;43m        <p><b>SparkContext</b></p>\u001B[39;49m\n\u001B[1;32m    381\u001B[0m \n\u001B[1;32m    382\u001B[0m \u001B[38;5;124;43m        <p><a href=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{sc.uiWebUrl}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m>Spark UI</a></p>\u001B[39;49m\n\u001B[1;32m    383\u001B[0m \n\u001B[1;32m    384\u001B[0m \u001B[38;5;124;43m        <dl>\u001B[39;49m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;124;43m          <dt>Version</dt>\u001B[39;49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;43m            <dd><code>v\u001B[39;49m\u001B[38;5;132;43;01m{sc.version}\u001B[39;49;00m\u001B[38;5;124;43m</code></dd>\u001B[39;49m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;124;43m          <dt>Master</dt>\u001B[39;49m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;124;43m            <dd><code>\u001B[39;49m\u001B[38;5;132;43;01m{sc.master}\u001B[39;49;00m\u001B[38;5;124;43m</code></dd>\u001B[39;49m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;124;43m          <dt>AppName</dt>\u001B[39;49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;124;43m            <dd><code>\u001B[39;49m\u001B[38;5;132;43;01m{sc.appName}\u001B[39;49;00m\u001B[38;5;124;43m</code></dd>\u001B[39;49m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;124;43m        </dl>\u001B[39;49m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;124;43m    </div>\u001B[39;49m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;124;43m    \u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43msc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/pyspark/context.py:530\u001B[0m, in \u001B[0;36mSparkContext.uiWebUrl\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21muiWebUrl\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    529\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the URL of the SparkUI instance started by this SparkContext\"\"\"\u001B[39;00m\n\u001B[0;32m--> 530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msc\u001B[49m()\u001B[38;5;241m.\u001B[39muiWebUrl()\u001B[38;5;241m.\u001B[39mget()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'sc'"
     ]
    },
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0xffff76fa6620>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 13:31:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0xffff7dc36710>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://35f587623013:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://spark-master:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-jupyter</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Директория с данными в workspace Jupyter\n",
    "BASE_DIR = './data/'\n",
    "# Название файла\n",
    "FILENAME = 'test.csv'\n",
    "# Полное имя файла\n",
    "file = f\"{BASE_DIR}{FILENAME}\"\n",
    "\n",
    "# Чтение файла\n",
    "spark_df = spark.read.csv(file, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T14:04:55.810628Z",
     "end_time": "2023-04-02T14:04:56.421754Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Запись в Jupyter workspace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['. gitkeep',\n 'book1-100k.csv',\n 'book1000k-1100k.csv',\n 'book100k-200k.csv',\n 'book1100k-1200k.csv',\n 'book1200k-1300k.csv',\n 'book1300k-1400k.csv',\n 'book1400k-1500k.csv',\n 'book1500k-1600k.csv',\n 'book1600k-1700k.csv',\n 'book1700k-1800k.csv',\n 'book1800k-1900k.csv',\n 'book1900k-2000k.csv',\n 'book2000k-3000k.csv',\n 'book200k-300k.csv',\n 'book3000k-4000k.csv',\n 'book300k-400k.csv',\n 'book4000k-5000k.csv',\n 'book400k-500k.csv',\n 'book500k-600k.csv',\n 'book600k-700k.csv',\n 'book700k-800k.csv',\n 'book800k-900k.csv',\n 'book900k-1000k.csv',\n 'user_rating_0_to_1000.csv',\n 'user_rating_1000_to_2000.csv',\n 'user_rating_2000_to_3000.csv',\n 'user_rating_3000_to_4000.csv',\n 'user_rating_4000_to_5000.csv',\n 'user_rating_5000_to_6000.csv',\n 'user_rating_6000_to_11000.csv']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME = 'test.csv'\n",
    "\n",
    "write_jupyter = (\n",
    "    spark_df.write.option(\"header\", True)\n",
    "    # .partitionBy(\"PublishYear\")\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f'{BASE_DIR}{FILENAME}')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:07:15.645505Z",
     "end_time": "2023-04-02T17:07:15.665465Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Чтение в Spark из Hadoop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['book1-100k.csv',\n 'book1000k-1100k.csv',\n 'book100k-200k.csv',\n 'book1100k-1200k.csv',\n 'book1200k-1300k.csv',\n 'book1300k-1400k.csv',\n 'book1400k-1500k.csv',\n 'book1500k-1600k.csv',\n 'book1600k-1700k.csv',\n 'book1700k-1800k.csv',\n 'book1800k-1900k.csv',\n 'book1900k-2000k.csv',\n 'book2000k-3000k.csv',\n 'book200k-300k.csv',\n 'book3000k-4000k.csv',\n 'book300k-400k.csv',\n 'book4000k-5000k.csv',\n 'book400k-500k.csv',\n 'book500k-600k.csv',\n 'book600k-700k.csv',\n 'book700k-800k.csv',\n 'book800k-900k.csv',\n 'book900k-1000k.csv']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Имя Hadoop Namenode в docker\n",
    "HADOOP_HOST = 'hadoop-namenode'\n",
    "# Hadoop Namenode port\n",
    "HADOOP_PORT = '9000'\n",
    "# Название файла\n",
    "FILENAME = 'test.parquet'\n",
    "\n",
    "spark_df = spark.read.parquet(f\"hdfs://{HADOOP_HOST}:{HADOOP_PORT}/{FILENAME}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T16:58:31.661057Z",
     "end_time": "2023-04-02T16:58:31.697707Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Запись в Hadoop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "['book1-100k.csv',\n 'book1000k-1100k.csv',\n 'book100k-200k.csv',\n 'book1100k-1200k.csv',\n 'book1200k-1300k.csv',\n 'book1300k-1400k.csv',\n 'book1400k-1500k.csv',\n 'book1500k-1600k.csv',\n 'book1600k-1700k.csv',\n 'book1700k-1800k.csv',\n 'book1800k-1900k.csv',\n 'book1900k-2000k.csv',\n 'book2000k-3000k.csv',\n 'book200k-300k.csv',\n 'book3000k-4000k.csv',\n 'book300k-400k.csv',\n 'book4000k-5000k.csv',\n 'book400k-500k.csv',\n 'book500k-600k.csv',\n 'book600k-700k.csv',\n 'book700k-800k.csv',\n 'book800k-900k.csv',\n 'book900k-1000k.csv']"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME = 'test.parquet'\n",
    "\n",
    "write_hadoop = (\n",
    "    spark_df.write.option(\"header\", True)\n",
    "    # .partitionBy(\"PublishYear\")\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"hdfs://{HADOOP_HOST}:{HADOOP_PORT}/{FILENAME}\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:15:07.940358Z",
     "end_time": "2023-04-02T17:15:07.980618Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Преобразовать данные исходного датасета в parquet объединяя все таблицы."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'book1-100k.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StructType, StructField, StringType\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbook_files\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m      4\u001B[0m     headers \u001B[38;5;241m=\u001B[39m file\u001B[38;5;241m.\u001B[39mreadline()\u001B[38;5;241m.\u001B[39mrstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m schema \u001B[38;5;241m=\u001B[39m StructType([StructField(header, StringType(), \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m header \u001B[38;5;129;01min\u001B[39;00m headers])\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'book1-100k.csv'"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T12:17:21.103321Z",
     "end_time": "2023-04-01T12:17:21.104738Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "получаем список файлов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['./data/book1-100k.csv',\n './data/book1400k-1500k.csv',\n './data/book1100k-1200k.csv',\n './data/book1800k-1900k.csv',\n './data/book1700k-1800k.csv',\n './data/book500k-600k.csv',\n './data/book1300k-1400k.csv',\n './data/book1000k-1100k.csv',\n './data/book700k-800k.csv',\n './data/book1500k-1600k.csv',\n './data/book1900k-2000k.csv',\n './data/book900k-1000k.csv',\n './data/book4000k-5000k.csv',\n './data/book400k-500k.csv',\n './data/book800k-900k.csv',\n './data/book1200k-1300k.csv',\n './data/book3000k-4000k.csv',\n './data/book600k-700k.csv',\n './data/book100k-200k.csv',\n './data/book300k-400k.csv',\n './data/book1600k-1700k.csv',\n './data/book2000k-3000k.csv',\n './data/book200k-300k.csv']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_list = [f\"{BASE_DIR}{file}\" for file in os.listdir(BASE_DIR) if 'book' in file]\n",
    "file_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T12:42:47.145686Z",
     "end_time": "2023-04-01T12:42:47.150987Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Берем схему из первого файла"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "with open(file_list[0]) as file:\n",
    "    headers = file.readline().rstrip().split(',')\n",
    "\n",
    "schema = StructType([StructField(header, StringType(), True) for header in headers])\n",
    "\n",
    "emp_RDD = spark.sparkContext.emptyRDD()\n",
    "\n",
    "spark_df = spark.createDataFrame(data = emp_RDD, schema=schema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T12:59:56.147666Z",
     "end_time": "2023-04-01T12:59:56.177887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+\n",
      "| Id|Name|RatingDist1|pagesNumber|RatingDist4|RatingDistTotal|PublishMonth|PublishDay|Publisher|CountsOfReview|PublishYear|Language|Authors|Rating|RatingDist2|RatingDist5|ISBN|RatingDist3|\n",
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+\n",
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T12:59:57.768271Z",
     "end_time": "2023-04-01T12:59:57.798520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    spark_data = spark.read.csv(file, header=True)\n",
    "    # spark_df = spark_df[headers]\n",
    "    spark_df = spark_df.unionByName(spark_data, allowMissingColumns=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T13:03:25.372208Z",
     "end_time": "2023-04-01T13:03:28.298769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark_df.write.option(\"header\", True)\n",
    "    # .partitionBy(\"PublishYear\")\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"hdfs://{HADOOP_HOST}:{HADOOP_PORT}/books.parquet\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T13:04:36.133080Z",
     "end_time": "2023-04-01T13:05:07.890825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "spark_df = spark_df.dropDuplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T14:11:02.118865Z",
     "end_time": "2023-04-01T14:11:02.153178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 156:==================================================>    (43 + 2) / 47]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " Id                    | 400000               \n",
      " Name                  | The Gigli Concert    \n",
      " RatingDist1           | 1:2                  \n",
      " pagesNumber           | 96                   \n",
      " RatingDist4           | 4:10                 \n",
      " RatingDistTotal       | total:27             \n",
      " PublishMonth          | 16                   \n",
      " PublishDay            | 9                    \n",
      " Publisher             | Bloomsbury Methue... \n",
      " CountsOfReview        | 2                    \n",
      " PublishYear           | 1991                 \n",
      " Language              | null                 \n",
      " Authors               | Tom    Murphy        \n",
      " Rating                | 3.3                  \n",
      " RatingDist2           | 2:4                  \n",
      " RatingDist5           | 5:3                  \n",
      " ISBN                  | 0413659305           \n",
      " RatingDist3           | 3:8                  \n",
      " Description           | null                 \n",
      " Count of text reviews | null                 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.filter(spark_df['Id'] == '400000').show(vertical=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T14:11:05.368895Z",
     "end_time": "2023-04-01T14:11:12.217506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "1873851"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T14:11:32.105836Z",
     "end_time": "2023-04-01T14:11:53.631567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "df_load = spark.read.parquet(f\"hdfs://{HADOOP_HOST}:{HADOOP_PORT}/books.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:46:56.980808Z",
     "end_time": "2023-04-01T00:46:57.269384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- RatingDist1: string (nullable = true)\n",
      " |-- pagesNumber: string (nullable = true)\n",
      " |-- RatingDist4: string (nullable = true)\n",
      " |-- RatingDistTotal: string (nullable = true)\n",
      " |-- PublishMonth: string (nullable = true)\n",
      " |-- PublishDay: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- CountsOfReview: string (nullable = true)\n",
      " |-- PublishYear: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- RatingDist2: string (nullable = true)\n",
      " |-- RatingDist5: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_load.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:46:58.422704Z",
     "end_time": "2023-04-01T00:46:58.433679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(Id='299975', Name=\"Visual C# 2005: A Developer's Notebook: A Developer's Notebook\", RatingDist1='1:1', pagesNumber='240', RatingDist4='4:5', RatingDistTotal='total:16', PublishMonth='2', PublishDay='5', Publisher=\"O'Reilly Media\", CountsOfReview='1', PublishYear='2005', Language=None, Authors='Jesse Liberty', Rating='3.44', RatingDist2='2:2', RatingDist5='5:3', ISBN='059600799X', RatingDist3='3:5'),\n Row(Id='299976', Name='Silent Joe', RatingDist1='1:33', pagesNumber='341', RatingDist4='4:725', RatingDistTotal='total:1780', PublishMonth='25', PublishDay='4', Publisher='Hyperion Books', CountsOfReview='124', PublishYear='2001', Language='eng', Authors='T. Jefferson Parker', Rating='3.85', RatingDist2='2:94', RatingDist5='5:476', ISBN='0786867280', RatingDist3='3:452'),\n Row(Id='299977', Name='A Silent Sorrow: Pregnancy Loss-- Guidance and Support for You and Your Family', RatingDist1='1:0', pagesNumber='299', RatingDist4='4:24', RatingDistTotal='total:62', PublishMonth='20', PublishDay='1', Publisher='Routledge', CountsOfReview='8', PublishYear='2000', Language=None, Authors='Ingrid Kohn', Rating='4.08', RatingDist2='2:3', RatingDist5='5:23', ISBN='0415924812', RatingDist3='3:12'),\n Row(Id='299979', Name='Ideal Suggestion Through Mental Photography', RatingDist1='1:0', pagesNumber='168', RatingDist4='4:2', RatingDistTotal='total:2', PublishMonth='10', PublishDay='8', Publisher='Kessinger Publishing', CountsOfReview='0', PublishYear='2003', Language=None, Authors='Henry Wood', Rating='4.0', RatingDist2='2:0', RatingDist5='5:0', ISBN='0766181111', RatingDist3='3:0'),\n Row(Id='299980', Name='Silent Warfare: Understanding the World of Intelligence', RatingDist1='1:4', pagesNumber='262', RatingDist4='4:75', RatingDistTotal='total:205', PublishMonth='1', PublishDay='5', Publisher='Potomac Books', CountsOfReview='8', PublishYear='2002', Language='en-GB', Authors='Abram N. Shulsky', Rating='3.63', RatingDist2='2:11', RatingDist5='5:37', ISBN='1574883453', RatingDist3='3:78'),\n Row(Id='299981', Name='Silent Sons: A Book for and About Men', RatingDist1='1:1', pagesNumber='240', RatingDist4='4:24', RatingDistTotal='total:73', PublishMonth='10', PublishDay='11', Publisher='Touchstone', CountsOfReview='4', PublishYear='1994', Language=None, Authors='Robert J. Ackerman', Rating='3.71', RatingDist2='2:6', RatingDist5='5:18', ISBN='067189286X', RatingDist3='3:24'),\n Row(Id='299982', Name='Walden and Civil Disobedience: Or, Life in the Woods', RatingDist1='1:1034', pagesNumber='320', RatingDist4='4:10957', RatingDistTotal='total:33833', PublishMonth='1', PublishDay='7', Publisher='Signet Classics', CountsOfReview='11', PublishYear='1999', Language=None, Authors='Henry David Thoreau', Rating='3.95', RatingDist2='2:2113', RatingDist5='5:12745', ISBN='0451527070', RatingDist3='3:6984'),\n Row(Id='299985', Name='The Channings', RatingDist1='1:2', pagesNumber='460', RatingDist4='4:10', RatingDistTotal='total:34', PublishMonth='15', PublishDay='11', Publisher='Wildside Press', CountsOfReview='0', PublishYear='2005', Language=None, Authors='Mrs. Henry Wood', Rating='3.8200000000000003', RatingDist2='2:4', RatingDist5='5:13', ISBN='1557424594', RatingDist3='3:5'),\n Row(Id='299992', Name='Bessy Rane', RatingDist1='1:0', pagesNumber='408', RatingDist4='4:1', RatingDistTotal='total:2', PublishMonth='1', PublishDay='3', Publisher='Wildside Press', CountsOfReview='0', PublishYear='2004', Language=None, Authors='Mrs. Henry Wood', Rating='3.5', RatingDist2='2:0', RatingDist5='5:0', ISBN='0809592703', RatingDist3='3:1'),\n Row(Id='299997', Name='Life More Abundant: Scriptural Truth In Modern Application', RatingDist1='1:0', pagesNumber='324', RatingDist4='4:0', RatingDistTotal='total:0', PublishMonth='9', PublishDay='7', Publisher='Kessinger Publishing', CountsOfReview='0', PublishYear='2006', Language=None, Authors='Henry Wood', Rating='0.0', RatingDist2='2:0', RatingDist5='5:0', ISBN='1428639551', RatingDist3='3:0')]"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load.tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:47:00.164066Z",
     "end_time": "2023-04-01T00:47:00.706084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------+-----------+------------------+-----------+---------------+------------+----------+----------------------------------+--------------+-----------+--------+--------------------+----------------------------------------------------+-----------+-----------+----+--------------------+\n",
      "|Id |Name                                                        |RatingDist1|pagesNumber       |RatingDist4|RatingDistTotal|PublishMonth|PublishDay|Publisher                         |CountsOfReview|PublishYear|Language|Authors             |Rating                                              |RatingDist2|RatingDist5|ISBN|RatingDist3         |\n",
      "+---+------------------------------------------------------------+-----------+------------------+-----------+---------------+------------+----------+----------------------------------+--------------+-----------+--------+--------------------+----------------------------------------------------+-----------+-----------+----+--------------------+\n",
      "|1  |Harry Potter and the Half-Blood Prince (Harry Potter, #6)   |1:9896     |652               |4:556485   |total:2298124  |16          |9         |Scholastic Inc.                   |28062         |2006       |eng     |J.K. Rowling        |4.57                                                |2:25317    |5:1546466  |null|3:159960            |\n",
      "|1  |2:3                                                         |2006       |160               |0810992612 |null           |4:38        |6         |\"\"\"Harry N. Abrams                |3:13          |164116     |4.04    |Jean-Louis Gailleman| Inc.\"\"\"                                            |1:0        |total:76   |12  |5:22                |\n",
      "|1  |\"Red Dawn at Lexington: \"\"If They Mean to Have a War        |4:8        |4.0               |213424     |total:16       |eng         |4         |Houghton Mifflin Harcourt (HMH)   |2:0           |3:4        |402     |3                   | Let It Begin Here!\"\"\"                              |0395388147 |5:4        |1:0 |Louis Birnbaum      |\n",
      "|1  |\"Ploplop No. 7: An \"\"Antholozine\"\" of Poetry                |4:0        |5.0               |220711     |total:1        |null        |12        |Geekspeak Unique Press            |2:0           |3:0        |50      |0                   | Prose and Artwork\"                                 |1885710143 |5:1        |1:0 |Steve Richmond      |\n",
      "|1  |\"\"\"\"\"City of the Century\"\"\"\": A History of Gary             |4:4        |3.7800000000000002|220766     |total:9        |null        |10        |Indiana University Press          |2:1           |3:2        |386     |0                   | Indiana\"                                           |0253111870 |5:2        |1:0 |James B. Lane       |\n",
      "|1  |\"Piano Trio No. 2 \"\"silent Voices\"\": For Violin             |4:0        |0.0               |233890     |total:0        |null        |8         |Boosey & Hawkes Inc               |2:0           |3:0        |40      |0                   | Violoncello and Piano\"                             |0634090127 |5:0        |1:0 |Benjamin Lees       |\n",
      "|1  |\"The \"\"Business\"\" of Sewing: How to Start                   |4:8        |3.74              |270331     |total:23       |null        |1         |Collins Pubn                      |2:3           |3:6        |2       |0                   | Achieve and Maintain Success\"                      |0971782415 |5:6        |1:0 |Barbara Wright Sykes|\n",
      "|1  |\"Joe Henderson - Selections from \"\"lush Life\"\" and \"\"so Near|4:0        |0.0               |283130     |total:0        |null        |8         |Hal Leonard Publishing Corporation|2:0           |3:0        |72      |0                   | So Far\"\": Tenor Sax\"                               |0793536561 |5:0        |1:0 |Ebb Kander          |\n",
      "|1  |\"\"\"V\"\" Is for Victory (Sweet Valley High                    |4:81       |3.71              |292386     |total:314      |null        |2         |Bantam                            |2:20          |3:118      |199     |5                   | #114)\"                                             |0553566326 |5:88       |1:7 |Francine Pascal     |\n",
      "|1  |\"Frieda Lawrence: Including \"\"Not I                         |4:2        |3.0               |295995     |total:7        |null        |11        |Rivers Oram Press                 |2:0           |3:4        |240     |0                   | But the Wind\"\" and Other Autobiographical Writings\"|004440915X |5:0        |1:1 |Rosemary Jackson    |\n",
      "|1  |\"No More \"\"Nice Girl\"\": Power                               |4:3        |4.0               |296473     |total:3        |null        |5         |Bob Adams Inc. Publishers         |2:0           |3:0        |192     |1                   | Sexuality and Success in the Workplace\"            |1558502440 |5:0        |1:0 |Rosemary Agonito    |\n",
      "+---+------------------------------------------------------------+-----------+------------------+-----------+---------------+------------+----------+----------------------------------+--------------+-----------+--------+--------------------+----------------------------------------------------+-----------+-----------+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_load.filter(df_load['Id'] == '1').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:47:34.501423Z",
     "end_time": "2023-04-01T00:47:35.140000Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "StructType([StructField('Id', StringType(), True), StructField('Name', StringType(), True), StructField('RatingDist1', StringType(), True), StructField('pagesNumber', StringType(), True), StructField('RatingDist4', StringType(), True), StructField('RatingDistTotal', StringType(), True), StructField('PublishMonth', StringType(), True), StructField('PublishDay', StringType(), True), StructField('Publisher', StringType(), True), StructField('CountsOfReview', StringType(), True), StructField('PublishYear', StringType(), True), StructField('Language', StringType(), True), StructField('Authors', StringType(), True), StructField('Rating', StringType(), True), StructField('RatingDist2', StringType(), True), StructField('RatingDist5', StringType(), True), StructField('ISBN', StringType(), True), StructField('RatingDist3', StringType(), True)])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T23:58:01.136748Z",
     "end_time": "2023-03-31T23:58:01.145675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('./data/book200k-300k.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:37:15.664699Z",
     "end_time": "2023-04-01T00:37:16.731357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "spark_df = spark_df[headers]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:37:35.126193Z",
     "end_time": "2023-04-01T00:37:35.229963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "Row(Id='200000', Name='Meet My Staff', RatingDist1='1:4', pagesNumber='40', RatingDist4='4:7', RatingDistTotal='total:27', PublishMonth='11', PublishDay=9, Publisher='HarperCollins', CountsOfReview='5', PublishYear='1998', Language=None, Authors='Patricia Marx', Rating='3.52', RatingDist2='2:3', RatingDist5='5:9', ISBN='0060274840', RatingDist3='3:4')"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:38:09.259996Z",
     "end_time": "2023-04-01T00:38:09.794704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- RatingDist1: string (nullable = true)\n",
      " |-- pagesNumber: string (nullable = true)\n",
      " |-- RatingDist4: string (nullable = true)\n",
      " |-- RatingDistTotal: string (nullable = true)\n",
      " |-- PublishMonth: string (nullable = true)\n",
      " |-- PublishDay: integer (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- CountsOfReview: string (nullable = true)\n",
      " |-- PublishYear: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- RatingDist2: string (nullable = true)\n",
      " |-- RatingDist5: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T00:37:40.641191Z",
     "end_time": "2023-04-01T00:37:40.649637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df1 = spark.read.csv('./data/book1-100k.csv', header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T23:49:50.967367Z",
     "end_time": "2023-03-31T23:49:52.208244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "spark_df2 = spark.read.csv('./data/book100k-200k.csv', header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T23:49:53.694952Z",
     "end_time": "2023-03-31T23:49:53.878029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "df3 = spark_df1.unionByName(spark_df2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T23:50:27.783586Z",
     "end_time": "2023-03-31T23:50:27.831950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------+-----------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+-----------+\n",
      "|Id |Name                                                        |RatingDist1|pagesNumber|RatingDist4|RatingDistTotal|PublishMonth|PublishDay|Publisher      |CountsOfReview|PublishYear|Language|Authors     |Rating|RatingDist2|RatingDist5|ISBN      |RatingDist3|\n",
      "+---+------------------------------------------------------------+-----------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+-----------+\n",
      "|2  |Harry Potter and the Order of the Phoenix (Harry Potter, #5)|1:12455    |870        |4:604283   |total:2358637  |1           |9         |Scholastic Inc.|29770         |2004       |eng     |J.K. Rowling|4.5   |2:37005    |5:1493113  |0439358078|3:211781   |\n",
      "+---+------------------------------------------------------------+-----------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.filter(df3['Id'] == '2').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T23:51:59.873364Z",
     "end_time": "2023-03-31T23:52:00.860442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pagesNumber: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- RatingDistTotal: string (nullable = true)\n",
      " |-- RatingDist5: string (nullable = true)\n",
      " |-- RatingDist3: string (nullable = true)\n",
      " |-- CountsOfReview: string (nullable = true)\n",
      " |-- PublishDay: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist4: string (nullable = true)\n",
      " |-- PublishMonth: string (nullable = true)\n",
      " |-- Id: string (nullable = true)\n",
      " |-- PublishYear: string (nullable = true)\n",
      " |-- RatingDist1: string (nullable = true)\n",
      " |-- RatingDist2: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df2.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T21:57:22.797228Z",
     "end_time": "2023-03-31T21:57:22.815046Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:==================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------+------------------------------------------------------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+----------------------------------------------------------------------------------+\n",
      "|Id |Name                                                        |RatingDist1                                           |pagesNumber|RatingDist4|RatingDistTotal|PublishMonth|PublishDay|Publisher      |CountsOfReview|PublishYear|Language|Authors     |Rating|RatingDist2|RatingDist5|ISBN      |RatingDist3                                                                       |\n",
      "+---+------------------------------------------------------------+------------------------------------------------------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+----------------------------------------------------------------------------------+\n",
      "|2  |Harry Potter and the Order of the Phoenix (Harry Potter, #5)|1:12455                                               |870        |4:604283   |total:2358637  |1           |9         |Scholastic Inc.|29770         |2004       |eng     |J.K. Rowling|4.5   |2:37005    |5:1493113  |0439358078|3:211781                                                                          |\n",
      "|2  |Gill Matthews                                               |David Fulton Publishers                               |0.0        |null       |total:0        |5:0         |3:0       |0              |6             |1843120569 |4:0     |29          |100439|2005       |1:0        |2:0       |Fantastic Beasts                                                                  |\n",
      "|2  |Alan  Campbell                                              |Ashgate Publishing                                    |0.0        |null       |total:0        |5:0         |3:0       |0              |1             |0754600173 |4:0     |1           |101666|1999       |1:0        |2:0       |British Trade Unions and Industrial Politics                                      |\n",
      "|2  |Huw Beynon                                                  |Edward Elgar Publishing                               |5.0        |null       |total:1        |5:1         |3:0       |0              |10            |1858989485 |4:0     |11          |101872|2006       |1:0        |2:0       |The Fordism of Ford and Modern Management: Fordism and Post-Fordism               |\n",
      "|2  |Michael Moorcock                                            |Wildside Press                                        |3.94       |null       |total:9345     |5:2771      |3:2370    |3              |11            |0809562464 |4:3740  |14          |102289|2006       |1:54       |2:410     |Elric Volume 2: The Sailor On The Seas Of Fate                                    |\n",
      "|2  |Robert E. Buswell Jr.                                       |MacMillan Reference Library                           |4.33       |null       |total:9        |5:5         |3:2       |3              |10            |0028657187 |4:2     |1           |103502|2003       |1:0        |2:0       |Encyclopedia of Buddhism                                                          |\n",
      "|2  |Jerry Goldman                                               |Northwestern University Press                         |4.0        |null       |total:2        |5:1         |3:1       |1              |12            |0810119617 |4:0     |11          |103937|2002       |1:0        |2:0       |The Supreme Court's Greatest Hits 2.0: Updated and Expanded                       |\n",
      "|2  |Edgar Cayce                                                 |A.R.E. Press (Association of Research & Enlightenment)|4.11       |null       |total:28       |5:13        |3:8       |2              |1             |0876040008 |4:6     |1           |104414|1989       |1:0        |2:1       |A Search for God, Book I                                                          |\n",
      "|2  |Garrison Keillor                                            |HighBridge Audio                                      |3.94       |en-US      |total:18       |5:4         |3:3       |3              |10            |1598870491 |4:10    |9           |105471|2006       |1:0        |2:1       |A Visit to Mark Twain's House                                                     |\n",
      "|2  |Agatha Christie                                             |BBC Audiobooks                                        |3.86       |eng        |total:26959    |5:6499      |3:8103    |5              |3             |0563510358 |4:11298 |7           |106697|2005       |1:109      |2:950     |A Pocket Full of Rye: A BBC Radio 4 Full-Cast Dramatisation                       |\n",
      "|2  |Mary Ely Peña-Gratereaux                                    |Civic Research Institute, Incorporated                |0.0        |null       |total:0        |5:0         |3:0       |0              |1             |1887554092 |4:0     |1           |107444|1999       |1:0        |2:0       |The Sexual Predator, Volume 1: Law, Policy, Evaluation and Treatment              |\n",
      "|2  |Paul Dale Bush                                              |Edward Elgar Publishing                               |3.0        |null       |total:1        |5:0         |3:1       |0              |8             |1858985617 |4:0     |1           |107919|1998       |1:0        |2:0       |Institutionalist Method and Value: Essays in Honor of Paul Dale Bush              |\n",
      "|2  |James Hewitt                                                |A-R Editions                                          |0.0        |null       |total:0        |5:0         |3:0       |0              |6             |089579098X |4:0     |1           |108001|1977       |1:0        |2:0       |Anthology of Early American Key Board Music 1787-1830                             |\n",
      "|2  |Clive Barker                                                |Audio Literature                                      |3.47       |null       |total:291      |5:70        |3:97      |30             |4             |0787118869 |4:71    |1           |108062|1999       |1:20       |2:33      |The History of the Devil                                                          |\n",
      "|2  |William Shakespeare                                         |HighBridge Classics                                   |4.25       |null       |total:80204    |5:40364     |3:11808   |0              |10            |1598870076 |4:24380 |10          |108177|2005       |1:1249     |2:2403    |Shakespeare's Sonnets                                                             |\n",
      "|2  |Helen MacGregor                                             |A&C Black                                             |4.26       |null       |total:57       |5:26        |3:9       |3              |1             |0713681950 |4:21    |1           |109101|2008       |1:0        |2:1       |Roald Dahl's Cinderella: A Clock Stopping, Show Stopping Musical                  |\n",
      "|2  |Norman Melchert                                             |Mayfield Publishing Company                           |3.96       |null       |total:171      |5:63        |3:31      |0              |1             |0767404688 |4:62    |1           |109590|1999       |1:8        |2:7       |The Great Conversation                                                            |\n",
      "|2  |John Stewart                                                |McFarland & Company                                   |5.0        |null       |total:1        |5:1         |3:0       |0              |12            |0899504701 |4:0     |1           |111061|1990       |1:0        |2:0       |Antarctica: An Encyclopedia                                                       |\n",
      "|2  |Margaret Atwood                                             |null                                                  |4.11       |eng        |total:1351314  |5:568839    |3:212169  |107            |12            |0886462142 |4:480175|1           |111261|1987       |1:30356    |2:59775   |The Handmaid's Tale                                                               |\n",
      "|2  |Rena Kornblum                                               |Wood 'N Barnes Publishing & Distribution              |4.25       |eng        |total:8        |5:3         |3:1       |0              |1             |1885473494 |4:4     |1           |116362|2003       |1:0        |2:0       |Disarming the Playground: Violence Prevention Through Movement & Pro-Social Skills|\n",
      "+---+------------------------------------------------------------+------------------------------------------------------+-----------+-----------+---------------+------------+----------+---------------+--------------+-----------+--------+------------+------+-----------+-----------+----------+----------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.filter(spark_df['Id'] == '2').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T22:50:09.613024Z",
     "end_time": "2023-03-31T22:50:15.532082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+\n",
      "|     Id|                Name|             Authors|      ISBN|Rating|PublishYear|PublishMonth|PublishDay|           Publisher|RatingDist5|RatingDist4|RatingDist3|RatingDist2|RatingDist1|RatingDistTotal|CountsOfReview|Language|PagesNumber|         Description|\n",
      "+-------+--------------------+--------------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+\n",
      "|4000000|      Top Management|     Bernard  Taylor|0582446058|   0.0|       1973|           1|         1|Longman Publishin...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        448|                null|\n",
      "|4000001|Celtic Warfare, 1...|  James Michael Hill|0859761517|  3.67|       1986|           1|         1|           J. Donald|        5:1|        4:1|        3:0|        2:1|        1:0|        total:3|             0|    null|        203|                null|\n",
      "|4000002|    Playwright Power|     Robert Friedman|0761803629|   0.0|       1996|           7|        28|University Press ...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        164|Playwright Power ...|\n",
      "|4000009|Selected Topics I...|         James Eells|0821807005|   0.0|       1983|           1|         1|American Mathemat...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|         85|Gives an account ...|\n",
      "|4000010|Foreign Exchange ...|Sylvester C.W. Ei...|1858988128|   0.0|       1999|           1|         1|Edward Elgar Publ...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        608|This collection o...|\n",
      "|4000015|Ludwig Tieck - St...|Thomas Gunther Zi...|3820498796|   0.0|       1987|          12|        31|Peter Lang Gmbh, ...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        377|Fur das Werk Ludw...|\n",
      "|4000018|Reality's Dark Dr...| William J. Lillyman|3110077108|   4.0|       1979|           1|         1|          de Gruyter|        5:0|        4:1|        3:0|        2:0|        1:0|        total:1|             0|    null|        171|                null|\n",
      "|4000021|Jonathan Edwards'...|      Norman Fiering|0807814733|  4.25|       1981|           1|         1|University of Nor...|        5:2|        4:1|        3:1|        2:0|        1:0|        total:4|             0|    null|        391|                null|\n",
      "|4000023|          Luis Palau|     W. Terry Whalin|1556618425|  4.33|       1996|           4|         1|Bethany House Pub...|        5:2|        4:4|        3:0|        2:0|        1:0|        total:6|             0|    null|        160|Discover the stor...|\n",
      "|4000025|A History Of The ...|William Russell A...|090064950X|   0.0|       1971|           1|         1|Scottish Library ...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        379|                null|\n",
      "|4000026|Ludwig Boltzmann:...|    Carlo Cercignani|0198501544|  3.64|       1998|          12|        10|Oxford University...|        5:4|       4:15|        3:6|        2:1|        1:2|       total:28|             0|    null|        352|Ludwig Boltzmann ...|\n",
      "|4000029|It's Who You Are ...|        James   Long|0310206014|   0.0|       1997|          12|        31|Zondervan Publish...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        149|\"A \"\"Deeper Devot...|\n",
      "|4000030|Twentieth Century...|        Geoff Sadler|0912289988|   4.0|       1992|           1|         1|     St. James Press|        5:0|        4:2|        3:0|        2:0|        1:0|        total:2|             0|    null|        848|This volume inclu...|\n",
      "|4000034|Ludwig Tieck: An ...|     Dwight A. Klett|0824056221|   0.0|       1993|           5|         1|           Routledge|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        224|                null|\n",
      "|4000039|Optimal Imperfect...|     George W. Downs|0691044600|   3.0|       1995|           9|        10|Princeton Univers...|        5:0|        4:0|        3:1|        2:0|        1:0|        total:1|             0|    null|        215|Domestic politics...|\n",
      "|4000040|Money Making Idea...|     Ronald J. Cooke|0773750231|   3.0|       1986|           4|         1|Longman Trade/Car...|        5:0|        4:0|        3:1|        2:0|        1:0|        total:1|             0|    null|        208|                null|\n",
      "|4000041|Randomised Contro...|Christopher J. Bu...|9024727499|   0.0|       1983|           3|        31|            Springer|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        272|\"Bradford Hill ha...|\n",
      "|4000042|A Staircase of Wo...|         Derek Beres|0981739822|   2.5|       2008|           5|        22|Outside the Box P...|        5:0|        4:1|        3:0|        2:0|        1:1|        total:2|             0|    null|        236|In his introducti...|\n",
      "|4000049|Michigan Butterfl...|   Mogens C. Nielsen|1565250125|   4.0|       1999|           1|         1|Msu Extension Mic...|        5:1|        4:1|        3:1|        2:0|        1:0|        total:3|             0|    null|        252|                null|\n",
      "|4000052| Sottsass Associates|     Ettore Sottsass|0847808920|   0.0|       1988|          12|        15|             Rizzoli|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        263|                null|\n",
      "+-------+--------------------+--------------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T16:02:36.483405Z",
     "end_time": "2023-03-31T16:02:37.017137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T14:46:44.717837Z",
     "end_time": "2023-03-31T14:46:45.195248Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connection to Spark Cluster\n",
    "\n",
    "To connect to the Spark cluster, create a SparkSession object with the following params:\n",
    "\n",
    "+ **appName:** application name displayed at the [Spark Master Web UI](http://localhost:8080/);\n",
    "+ **master:** Spark Master URL, same used by Spark Workers;\n",
    "+ **spark.executor.memory:** must be less than or equals to docker compose SPARK_WORKER_MEMORY config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Store Data\n",
    "We will now load data from a local CSV and store it to Hadoop partitioned by column.\n",
    "Afterward you can access Hadoop UI to explore the saved parquet files.\n",
    "Access Hadoop UI on 'http://localhost:9870' (Utilities -> Browse the files system )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import time    \n",
    "epochNow = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over all files until we find the sales file and then creates a Pandas dataframe.\n",
    "for path, subdirs, files in os.walk('./data/'):\n",
    "    for name in files:\n",
    "        if \"salesRecord\" in name:\n",
    "            csvName = name\n",
    "            csvPath = os.path.join(path, name)\n",
    "            print(\"Loading data from csv {}\".format(csvPath))\n",
    "            salesDfPandas = pandas.read_csv(csvPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create PySpark DataFrame from Pandas\n",
    "salesDfSpark=spark.createDataFrame(salesDfPandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove spaces in column names\n",
    "salesDfSpark = salesDfSpark.select([F.col(col).alias(col.replace(' ', '_')) for col in salesDfSpark.columns])\n",
    "print(\"Sales Dataframe created with schema : \")\n",
    "salesDfSpark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Dataframe into HDFS\n",
    "# Repartition it by \"Country\" column before storing as parquet files in Hadoop\n",
    "salesDfSpark.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"Country\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"hdfs://hadoop-namenode:9000/sales/{}_{}.parquet\".format(csvName,epochNow))\n",
    "print(\"Sales Dataframe stored in Hadoop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from HDFS to confirm it was successfully stored\n",
    "df_load = spark.read.parquet(\"hdfs://hadoop-namenode:9000/sales/{}_{}.parquet\".format(csvName,epochNow))\n",
    "print(\"Sales Dataframe read from Hadoop : \")\n",
    "df_load.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
